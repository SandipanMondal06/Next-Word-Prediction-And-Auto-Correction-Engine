{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install textdistance\n",
        "!pip install metaphone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7y2LDR-gJ7C",
        "outputId": "3384e14d-a575-4210-d6c9-6fcf8646c7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textdistance\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Downloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: textdistance\n",
            "Successfully installed textdistance-4.6.3\n",
            "Collecting metaphone\n",
            "  Downloading Metaphone-0.6.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: metaphone\n",
            "  Building wheel for metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13901 sha256=dc4d0d7f95484e909415fd2d04d64df3df4722f0110d619898f683dfb77ca712\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/cb/f9/3ce2de290cd1b6f10dd8ed4795f3dec4a835b02d2514f9b9d3\n",
            "Successfully built metaphone\n",
            "Installing collected packages: metaphone\n",
            "Successfully installed metaphone-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import textdistance\n",
        "import pandas as pd\n",
        "from metaphone import doublemetaphone\n",
        "import difflib\n",
        "\n",
        "def install_packages():\n",
        "    packages = ['metaphone', 'textdistance', 'nltk', 'matplotlib', 'pandas']\n",
        "    for package in packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "        except ImportError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "\n",
        "install_packages()\n",
        "\n",
        "def load_corpus(file_path=\"/content/corpus.txt\"):\n",
        "    \"\"\"Load corpus with fallback to default if file not found\"\"\"\n",
        "    try:\n",
        "        file_path = Path(file_path)\n",
        "        if not file_path.exists():\n",
        "            alt_paths = [\"corpus.txt\", \"./data/corpus.txt\", \"text_data.txt\"]\n",
        "            for alt_path in alt_paths:\n",
        "                if Path(alt_path).exists():\n",
        "                    file_path = Path(alt_path)\n",
        "                    break\n",
        "            else:\n",
        "                return \"\"\"\n",
        "                Natural language processing is a field of artificial intelligence that focuses on\n",
        "                interaction between computers and humans through natural language. Machine learning\n",
        "                algorithms are used to analyze and understand human language. Text processing involves\n",
        "                cleaning and preparing text data for analysis. Word frequency analysis helps identify\n",
        "                common words in text. Autocorrect systems use various techniques including edit distance,\n",
        "                phonetic matching, and statistical models to suggest corrections for misspelled words.\n",
        "                Spell checking is important feature in many applications. Context aware suggestions can\n",
        "                improve accuracy of autocorrect systems. Bigram models help predict next word based on\n",
        "                previous word. Natural language understanding requires sophisticated algorithms and large\n",
        "                amounts of training data. Machine learning models can be trained on large text corpora\n",
        "                to learn patterns in language use. Programming languages like Python provide excellent\n",
        "                tools for natural language processing tasks. Computer science students learn about\n",
        "                artificial intelligence and machine learning concepts. Data science involves analyzing\n",
        "                large datasets to extract meaningful insights. Software engineering requires good\n",
        "                programming skills and system design knowledge.\n",
        "                \"\"\"\n",
        "\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            return file.read()\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"\"\"\n",
        "        Natural language processing is a field of artificial intelligence that focuses on\n",
        "        interaction between computers and humans through natural language. Machine learning\n",
        "        algorithms are used to analyze and understand human language.\n",
        "        \"\"\"\n",
        "\n",
        "# Initialize the system\n",
        "file_content = load_corpus()\n",
        "words = re.findall(r'\\w+', file_content.lower())\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [w for w in words if w.isalpha() and w not in stop_words and len(w) > 2]\n",
        "vocabulary = set(filtered_words)\n",
        "word_freq = Counter(filtered_words)\n",
        "total_count = sum(word_freq.values())\n",
        "probs = {word: freq/total_count for word, freq in word_freq.items()}\n",
        "\n",
        "def build_bigram_model(tokens):\n",
        "    bigram_counts = defaultdict(Counter)\n",
        "    for w1, w2 in zip(tokens[:-1], tokens[1:]):\n",
        "        bigram_counts[w1][w2] += 1\n",
        "    return bigram_counts\n",
        "\n",
        "bigram_counts = build_bigram_model(filtered_words)\n",
        "\n",
        "def phonetic_candidates(word, vocab):\n",
        "    try:\n",
        "        word_code = doublemetaphone(word)\n",
        "        candidates = []\n",
        "        for w in vocab:\n",
        "            code = doublemetaphone(w)\n",
        "            if code[0] == word_code[0] or (word_code[1] and code[1] == word_code[1]):\n",
        "                candidates.append(w)\n",
        "        return candidates\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def check_spelling(input_text):\n",
        "    \"\"\"Check if word/sentence is correct or provide corrections\"\"\"\n",
        "    input_words = re.findall(r'\\w+', input_text.lower())\n",
        "\n",
        "    if len(input_words) == 1:\n",
        "        # Single word\n",
        "        word = input_words[0]\n",
        "        if word in vocabulary:\n",
        "            return \"Correct\"\n",
        "        else:\n",
        "            # Find best suggestion\n",
        "            similarity_scores = {\n",
        "                w: textdistance.levenshtein.normalized_similarity(word, w)\n",
        "                for w in word_freq.keys()\n",
        "            }\n",
        "\n",
        "            phonetic_matches = phonetic_candidates(word, vocabulary)\n",
        "            for pm in phonetic_matches:\n",
        "                similarity_scores[pm] = max(similarity_scores.get(pm, 0), 0.9)\n",
        "\n",
        "            close_matches = difflib.get_close_matches(word, list(vocabulary), n=3, cutoff=0.6)\n",
        "\n",
        "            best_suggestions = sorted(\n",
        "                similarity_scores.items(),\n",
        "                key=lambda x: (x[1], word_freq.get(x[0], 0)),\n",
        "                reverse=True\n",
        "            )[:3]\n",
        "\n",
        "            if close_matches:\n",
        "                return close_matches[0]\n",
        "            elif best_suggestions:\n",
        "                return best_suggestions[0][0]\n",
        "            else:\n",
        "                return word\n",
        "\n",
        "    else:\n",
        "        # Multiple words (sentence)\n",
        "        corrected_words = []\n",
        "        all_correct = True\n",
        "\n",
        "        for word in input_words:\n",
        "            if word in vocabulary:\n",
        "                corrected_words.append(word)\n",
        "            else:\n",
        "                all_correct = False\n",
        "                close_matches = difflib.get_close_matches(word, list(vocabulary), n=1, cutoff=0.6)\n",
        "                if close_matches:\n",
        "                    corrected_words.append(close_matches[0])\n",
        "                else:\n",
        "                    # Use similarity scoring\n",
        "                    similarity_scores = {\n",
        "                        w: textdistance.levenshtein.normalized_similarity(word, w)\n",
        "                        for w in list(vocabulary)[:1000]  # Limit for performance\n",
        "                    }\n",
        "                    best_match = max(similarity_scores.items(), key=lambda x: x[1])\n",
        "                    if best_match[1] > 0.5:\n",
        "                        corrected_words.append(best_match[0])\n",
        "                    else:\n",
        "                        corrected_words.append(word)\n",
        "\n",
        "        if all_correct:\n",
        "            return \"Correct\"\n",
        "        else:\n",
        "            return ' '.join(corrected_words)\n",
        "\n",
        "def predict_next_word(input_text):\n",
        "    \"\"\"Predict next word based on the last word in input\"\"\"\n",
        "    words_in_input = re.findall(r'\\w+', input_text.lower())\n",
        "    if not words_in_input:\n",
        "        return \"No input provided\"\n",
        "\n",
        "    last_word = words_in_input[-1]\n",
        "\n",
        "    if last_word in bigram_counts:\n",
        "        predictions = [w for w, _ in bigram_counts[last_word].most_common(3)]\n",
        "        if predictions:\n",
        "            return predictions\n",
        "        else:\n",
        "            # Fallback to most common words\n",
        "            return [w for w, _ in word_freq.most_common(3)]\n",
        "    else:\n",
        "        # If word not in bigram model, suggest most common words\n",
        "        return [w for w, _ in word_freq.most_common(3)]\n",
        "\n",
        "def complete_word(input_text):\n",
        "    \"\"\"Complete partial word or suggest completions\"\"\"\n",
        "    words_in_input = input_text.strip().split()\n",
        "    if not words_in_input:\n",
        "        return \"No input provided\"\n",
        "\n",
        "    last_word = words_in_input[-1].lower()\n",
        "\n",
        "    # Find words that start with the partial word\n",
        "    completions = [w for w in vocabulary if w.startswith(last_word)]\n",
        "\n",
        "    if not completions:\n",
        "        # If no direct completions, find similar words\n",
        "        similarity_scores = {\n",
        "            w: textdistance.jaccard(last_word, w)\n",
        "            for w in vocabulary\n",
        "            if w.startswith(last_word[:2])  # At least first 2 characters match\n",
        "        }\n",
        "\n",
        "        if similarity_scores:\n",
        "            best_matches = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "            completions = [match[0] for match in best_matches]\n",
        "\n",
        "    # Sort by frequency\n",
        "    completions.sort(key=lambda w: word_freq.get(w, 0), reverse=True)\n",
        "\n",
        "    if completions:\n",
        "        if last_word in completions:\n",
        "            # If the word is already complete, return it\n",
        "            return last_word\n",
        "        else:\n",
        "            # Return top 3 completions\n",
        "            return completions[:3]\n",
        "    else:\n",
        "        return \"No completions found\"\n",
        "\n",
        "def run_autocorrect_system():\n",
        "    \"\"\"Main interactive function\"\"\"\n",
        "    print(\"=\"*50)\n",
        "    print(\"        AUTOCORRECT SYSTEM\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"System initialized successfully!\")\n",
        "    print(f\"Vocabulary size: {len(vocabulary)} words\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "        # Get user input\n",
        "        user_input = input(\"Enter a word or sentence (or 'quit' to exit): \").strip()\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"\\nThank you for using Autocorrect System!\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            print(\"Please enter some text.\")\n",
        "            continue\n",
        "\n",
        "        print(\"-\"*50)\n",
        "        print(\"Choose an option:\")\n",
        "        print(\"1. Check correct or not\")\n",
        "        print(\"2. Next word\")\n",
        "        print(\"3. Complete word\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        choice = input(\"Enter your choice (1/2/3): \").strip()\n",
        "\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        if choice == '1':\n",
        "            result = check_spelling(user_input)\n",
        "            print(f\"Input: '{user_input}'\")\n",
        "            if result == \"Correct\":\n",
        "                print(\"✓ Correct\")\n",
        "            else:\n",
        "                print(f\"✗ Suggestion: '{result}'\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            predictions = predict_next_word(user_input)\n",
        "            print(f\"Input: '{user_input}'\")\n",
        "            if isinstance(predictions, list):\n",
        "                print(f\"Next word predictions: {', '.join(predictions)}\")\n",
        "            else:\n",
        "                print(f\"Next word prediction: {predictions}\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            completions = complete_word(user_input)\n",
        "            print(f\"Input: '{user_input}'\")\n",
        "            if isinstance(completions, list):\n",
        "                print(f\"Word completions: {', '.join(completions)}\")\n",
        "            else:\n",
        "                print(f\"Word completion: {completions}\")\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
        "\n",
        "        print(\"-\"*50)\n",
        "        continue_choice = input(\"Continue? (y/n): \").strip().lower()\n",
        "        if continue_choice in ['n', 'no']:\n",
        "            print(\"\\nThank you for using Autocorrect System!\")\n",
        "            break\n",
        "\n"
      ],
      "metadata": {
        "id": "9BjHtq1kO5kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    run_autocorrect_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiW-R8RLO7R8",
        "outputId": "19755506-719a-4d1b-811b-8e53bb6c10ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "        AUTOCORRECT SYSTEM\n",
            "==================================================\n",
            "System initialized successfully!\n",
            "Vocabulary size: 132694 words\n",
            "--------------------------------------------------\n",
            "\n",
            "==================================================\n",
            "Enter a word or sentence (or 'quit' to exit): Fuck\n",
            "--------------------------------------------------\n",
            "Choose an option:\n",
            "1. Check correct or not\n",
            "2. Next word\n",
            "3. Complete word\n",
            "--------------------------------------------------\n",
            "Enter your choice (1/2/3): 2\n",
            "--------------------------------------------------\n",
            "Input: 'Fuck'\n",
            "Next word predictions: program, tha, goddamn\n",
            "--------------------------------------------------\n",
            "Continue? (y/n): y\n",
            "\n",
            "==================================================\n",
            "Enter a word or sentence (or 'quit' to exit): facuk\n",
            "--------------------------------------------------\n",
            "Choose an option:\n",
            "1. Check correct or not\n",
            "2. Next word\n",
            "3. Complete word\n",
            "--------------------------------------------------\n",
            "Enter your choice (1/2/3): 1\n",
            "--------------------------------------------------\n",
            "Input: 'facuk'\n",
            "✗ Suggestion: 'fack'\n",
            "--------------------------------------------------\n",
            "Continue? (y/n): y\n",
            "\n",
            "==================================================\n",
            "Enter a word or sentence (or 'quit' to exit): quit\n",
            "\n",
            "Thank you for using Autocorrect System!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwvxTMZBgYgB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}